{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "colab": {
      "name": "Tarea5_IC_of.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wElmoTbv1Fq7"
      },
      "source": [
        "# Tarea 5\n",
        "## Clustering\n",
        "### María José Liberona"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXgHWCog1f9Y"
      },
      "source": [
        "## Importación librerías\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKKJmyO40-Lm"
      },
      "source": [
        "#Librerías\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_digits\n",
        "from time import time\n",
        "from sklearn import metrics\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReDBncpH17Eq"
      },
      "source": [
        "## Subir y leer archivo\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "YYyN_i4t2EaH",
        "outputId": "2d0cf84b-649a-40a3-d173-c961f576d088"
      },
      "source": [
        "#Subir archivo \n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # Frogs_MFCCs.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f11f8302-bf98-4b8f-851b-f274a2e6fbe5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f11f8302-bf98-4b8f-851b-f274a2e6fbe5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Frogs_MFCCs.csv to Frogs_MFCCs.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcnE7wyW6DTu",
        "outputId": "d4cac614-d3e6-49de-8130-03483bba8e12"
      },
      "source": [
        "#Leer archivo csv\n",
        "data=pd.read_csv('Frogs_MFCCs.csv')\n",
        "\n",
        "#Divide la data en características (MFCCs_1-MFCCs_22) y labels (Species)\n",
        "MFCCs_data=data.iloc[:,:22]\n",
        "labels_data=data.iloc[:,24]\n",
        "\n",
        "#Reemplazo de las especies por números de 0 a 9\n",
        "labels_data.loc[labels_data=='AdenomeraAndre']=0\n",
        "labels_data.loc[labels_data=='AdenomeraHylaedactylus']=1\n",
        "labels_data.loc[labels_data=='Ameeregatrivittata']=2\n",
        "labels_data.loc[labels_data=='HylaMinuta']=3\n",
        "labels_data.loc[labels_data=='HypsiboasCinerascens']=4\n",
        "labels_data.loc[labels_data=='HypsiboasCordobae']=5\n",
        "labels_data.loc[labels_data=='LeptodactylusFuscus']=6\n",
        "labels_data.loc[labels_data=='OsteocephalusOophagus']=7\n",
        "labels_data.loc[labels_data=='Rhinellagranulosa']=8\n",
        "labels_data.loc[labels_data=='ScinaxRuber']=9\n",
        "\n",
        "labels_data=labels_data.to_numpy().astype(int)\n",
        "#Muestra los datos\n",
        "print(MFCCs_data)\n",
        "print(labels_data)\n",
        "\n",
        "#Columnas\n",
        "columnas_data=[\"MFCCs_\" + str(i) for i in range(1,23)] #Nombre de las características\n",
        "print(columnas_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      MFCCs_ 1  MFCCs_ 2  MFCCs_ 3  ...  MFCCs_20  MFCCs_21  MFCCs_22\n",
            "0          1.0  0.152936 -0.105586  ...  0.057684  0.118680  0.014038\n",
            "1          1.0  0.171534 -0.098975  ...  0.020140  0.082263  0.029056\n",
            "2          1.0  0.152317 -0.082973  ... -0.025083  0.099108  0.077162\n",
            "3          1.0  0.224392  0.118985  ... -0.054766 -0.018691  0.023954\n",
            "4          1.0  0.087817 -0.068345  ... -0.031346  0.108610  0.079244\n",
            "...        ...       ...       ...  ...       ...       ...       ...\n",
            "7190       1.0 -0.554504 -0.337717  ...  0.052449 -0.021860 -0.079860\n",
            "7191       1.0 -0.517273 -0.370574  ...  0.046461 -0.015418 -0.101892\n",
            "7192       1.0 -0.582557 -0.343237  ...  0.027834 -0.000531 -0.080425\n",
            "7193       1.0 -0.519497 -0.307553  ...  0.041803 -0.027911 -0.096895\n",
            "7194       1.0 -0.508833 -0.324106  ...  0.031560 -0.029355 -0.087910\n",
            "\n",
            "[7195 rows x 22 columns]\n",
            "[0 0 0 ... 9 9 9]\n",
            "['MFCCs_1', 'MFCCs_2', 'MFCCs_3', 'MFCCs_4', 'MFCCs_5', 'MFCCs_6', 'MFCCs_7', 'MFCCs_8', 'MFCCs_9', 'MFCCs_10', 'MFCCs_11', 'MFCCs_12', 'MFCCs_13', 'MFCCs_14', 'MFCCs_15', 'MFCCs_16', 'MFCCs_17', 'MFCCs_18', 'MFCCs_19', 'MFCCs_20', 'MFCCs_21', 'MFCCs_22']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRU6cRtL0-Ls"
      },
      "source": [
        "## Define our evaluation benchmark\n",
        "\n",
        "We will first our evaluation benchmark. During this benchmark, we intend to\n",
        "compare different initialization methods for KMeans. Our benchmark will:\n",
        "\n",
        "* create a pipeline which will scale the data using a\n",
        "  :class:`~sklearn.preprocessing.StandardScaler`;\n",
        "* train and time the pipeline fitting;\n",
        "* measure the performance of the clustering obtained via different metrics.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GydiDDQk0-Lt"
      },
      "source": [
        "def bench_k_means(kmeans, name, data, labels):\n",
        "    \"\"\"Benchmark to evaluate the KMeans initialization methods.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    kmeans : KMeans instance\n",
        "        A :class:`~sklearn.cluster.KMeans` instance with the initialization\n",
        "        already set.\n",
        "    name : str\n",
        "        Name given to the strategy. It will be used to show the results in a\n",
        "        table.\n",
        "    data : ndarray of shape (n_samples, n_features)\n",
        "        The data to cluster.\n",
        "    labels : ndarray of shape (n_samples,)\n",
        "        The labels used to compute the clustering metrics which requires some\n",
        "        supervision.\n",
        "    \"\"\"\n",
        "    t0 = time() #Tiempo de inicio \n",
        "    estimator = make_pipeline(StandardScaler(), kmeans).fit(data) #Estima y normaliza los datos\n",
        "    fit_time = time() - t0 #Calcula el tiempo de entrenamiento\n",
        "    results = [name, fit_time, estimator[-1].inertia_] #resultados\n",
        "    n_clusters= len(set((estimator[-1].labels_))) # número de clusters\n",
        "\n",
        "    # Define the metrics which require only the true labels and estimator\n",
        "    # labels\n",
        "    clustering_metrics = [\n",
        "        metrics.homogeneity_score,\n",
        "        metrics.completeness_score,\n",
        "        metrics.v_measure_score,\n",
        "        metrics.adjusted_rand_score,\n",
        "        metrics.adjusted_mutual_info_score\n",
        "    ]\n",
        "    results += [m(labels, estimator[-1].labels_) for m in clustering_metrics] #Calcula el valor de los clusters a partir del clustering Kmeans\n",
        "    #print(results)\n",
        "    # The silhouette score requires the full dataset\n",
        "    results += [\n",
        "        metrics.silhouette_score(data, estimator[-1].labels_,\n",
        "                                 metric=\"euclidean\", sample_size=300,)\n",
        "    ]\n",
        "\n",
        "    results += [n_clusters]\n",
        "    # Show the results\n",
        "    formatter_result = (\"{:15s}\\t\\t{:.3f}s\\t{:.0f}\\t{:.3f}\\t{:.3f}\"\n",
        "                        \"\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t\\t{:.0f}\")\n",
        "    print(formatter_result.format(*results))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_bfWOpr0-Lt"
      },
      "source": [
        "## Run the benchmark\n",
        "\n",
        "We will compare three approaches:\n",
        "\n",
        "* an initialization using `kmeans++`. This method is stochastic and we will\n",
        "  run the initialization 4 times;\n",
        "* a random initialization. This method is stochastic as well and we will run\n",
        "  the initialization 4 times;\n",
        "* an initialization based on a :class:`~sklearn.decomposition.PCA`\n",
        "  projection. Indeed, we will use the components of the\n",
        "  :class:`~sklearn.decomposition.PCA` to initialize KMeans. This method is\n",
        "  deterministic and a single initialization suffice.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFIQUjQQ0-Lu",
        "outputId": "7023506a-0026-41a9-a5a5-0eb0d19fe5e8"
      },
      "source": [
        "#Ejemplo\n",
        "print(105 * '_')\n",
        "print('init\\t\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsilhouette\\tclusters')\n",
        "\n",
        "kmeans = KMeans(init=\"k-means++\", n_clusters=10, n_init=4,\n",
        "                random_state=0)\n",
        "bench_k_means(kmeans=kmeans, name=\"k-means++\", data=MFCCs_data, labels=labels_data)\n",
        "\n",
        "kmeans = KMeans(init=\"random\", n_clusters=10, n_init=4, random_state=0)\n",
        "bench_k_means(kmeans=kmeans, name=\"random\", data=MFCCs_data, labels=labels_data)\n",
        "\n",
        "pca = PCA(n_components=10).fit(MFCCs_data)\n",
        "kmeans = KMeans(init=pca.components_, n_clusters=10, n_init=1)\n",
        "bench_k_means(kmeans=kmeans, name=\"PCA-based\", data=MFCCs_data, labels=labels_data)\n",
        "\n",
        "print(105 * '_')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________________________________________________\n",
            "init\t\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsilhouette\tclusters\n",
            "k-means++      \t\t0.274s\t51996\t0.708\t0.571\t0.633\t0.432\t0.631\t0.225\t\t10\n",
            "random         \t\t0.306s\t54400\t0.641\t0.507\t0.566\t0.326\t0.565\t0.195\t\t10\n",
            "PCA-based      \t\t0.080s\t58266\t0.720\t0.698\t0.709\t0.863\t0.708\t0.387\t\t10\n",
            "_________________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojsIMT1iPpR3"
      },
      "source": [
        "## Función bench_clustering2()\n",
        "\n",
        "Basándose en la función bench_k_means() considerando las siguientes indicaciones:\n",
        "\n",
        "a) DBSCAN no posee la variable inertia._\n",
        "b) DBSCAN no asigna todas las muestras a un cluster, las muestras no asociadas tienen label '-1', por ello debe entregar la opción de: (i) Calcular las métricas sólo con los datos asociados o (ii) calcular las métricas usando todos los datos, asumiendo que los datos no asociados conforman un cluster extra. Dicha opción debe ser implementada usando una variable extra (True/False) que se le entrega a la función.\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UIxese2XRxa"
      },
      "source": [
        "def bench_clustering2(fc, name, data, labels, all): #Función que sirve para el DBSCAN y el método aglomerativo\n",
        "    \"\"\"Benchmark to evaluate the KMeans initialization methods.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    db or agg : DBSCAN instance\n",
        "        A :class:`~sklearn.cluster.KMeans` instance with the initialization\n",
        "        already set.\n",
        "    name : str\n",
        "        Name given to the strategy. It will be used to show the results in a\n",
        "        table.\n",
        "    data : ndarray of shape (n_samples, n_features)\n",
        "        The data to cluster.\n",
        "    labels : ndarray of shape (n_samples,)\n",
        "        The labels used to compute the clustering metrics which requires some\n",
        "        supervision.\n",
        "    \"\"\"\n",
        "\n",
        "    t0 = time() #Tiempo de inicio \n",
        "    data_n=StandardScaler().fit_transform(data) #Normaliza los datos\n",
        "    estimator = fc.fit(data_n) #Entrena el estimador a partir de los datos normalizados\n",
        "    fit_time = time() - t0 #Tiempo de entrenamiento\n",
        "    labels_pred=np.array(estimator.labels_).astype(int) #Predice el labels de cada muestra\n",
        "    largo=len(labels_pred) \n",
        "    #print(labels_pred)\n",
        "    results = [name, fit_time, np.nan]\n",
        "    try:\n",
        "      #Antes de calcular las métricas se debe considerar si se requiere utilizar todos los datos o no\n",
        "      if all==True: #Considera todas las muestras\n",
        "        labels_pred[labels_pred==-1]=max(set(labels_pred))+1 #Cambia los -1 al n° mayor de cluster+1\n",
        "        #Se redefinen los arreglos\n",
        "        data_n1=data_n\n",
        "        labels_data1=labels_data\n",
        "        labels_pred1=labels_pred\n",
        "        #print(set(labels_pred))\n",
        "        n_clusters= len(set(labels_pred1)) #Calcula el total de clusters\n",
        "\n",
        "      elif all==False: #No considera todas las muestras\n",
        "        data_n1=pd.DataFrame([]) \n",
        "        labels_data1=np.array([])\n",
        "        labels_pred1=np.array([])\n",
        "        for i in range(largo):\n",
        "          if labels_pred[i]!=-1: #Si tiene asignado un cluster entonces se agrega el dato \n",
        "            data_n1=data_n1.append(pd.Series(data_n[i,:]), ignore_index=True)\n",
        "            labels_data1=np.append(labels_data1,labels_data[i])\n",
        "            labels_pred1=np.append(labels_pred1, labels_pred[i])\n",
        "        n_clusters= len(set(labels_pred1))\n",
        "      # Define the metrics which require only the true labels and estimator\n",
        "      # labels\n",
        "\n",
        "      clustering_metrics = [\n",
        "          metrics.homogeneity_score,\n",
        "          metrics.completeness_score,\n",
        "          metrics.v_measure_score,\n",
        "          metrics.adjusted_rand_score,\n",
        "          metrics.adjusted_mutual_info_score\n",
        "      ]\n",
        "      results += [m(labels_data1, labels_pred1) for m in clustering_metrics] #Calcula las métricas a partir de las predicciones y labels originales\n",
        "\n",
        "      # The silhouette score requires the full dataset\n",
        "      if n_clusters==0 or n_clusters==1: #Si n_clusters da 0 o 1\n",
        "        results +=[np.nan]\n",
        "\n",
        "      else:\n",
        "        results += [\n",
        "            metrics.silhouette_score(data_n1, labels_pred1,\n",
        "                                  metric=\"euclidean\", sample_size=300,)\n",
        "        ]\n",
        "      \n",
        "      #Añade n_clusters en la tabla\n",
        "      results += [n_clusters]\n",
        "      # Show the results\n",
        "      formatter_result = (\"{:15s}\\t\\t{:.3f}s\\t{:.3f}\\t{:.3f}\\t{:.3f}\"\n",
        "                          \"\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t\\t{:.0f}\")\n",
        "      print(formatter_result.format(*results))\n",
        "    \n",
        "    except:\n",
        "      print(str(name)+'          No se pueden calcular las métricas')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dPO9fdpey_i",
        "outputId": "8b415537-0593-4930-9ad5-7d95b427026a"
      },
      "source": [
        "#Ejemplo\n",
        "print(105 * '_')\n",
        "print('init\\t\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsilhouette\\tclusters')\n",
        "\n",
        "db = DBSCAN(eps=0.5)\n",
        "bench_clustering2(fc=db, name=\"DBSCAN\", data=MFCCs_data, labels=labels_data, all=True)\n",
        "\n",
        "Agg = AgglomerativeClustering(n_clusters=10)\n",
        "bench_clustering2(fc=Agg, name=\"Aglomerativo\", data=MFCCs_data, labels=labels_data, all=True)\n",
        "\n",
        "print(105 * '_')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________________________________________________\n",
            "init\t\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsilhouette\tclusters\n",
            "DBSCAN         \t\t0.579s\tnan\t0.074\t0.451\t0.127\t0.049\t0.123\t-0.212\t\t9\n",
            "Aglomerativo   \t\t2.205s\tnan\t0.789\t0.661\t0.719\t0.590\t0.718\t0.308\t\t10\n",
            "_________________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f5yYBr6ixTi"
      },
      "source": [
        "## Pruebas con distintas variantes de algoritmos\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNfKbqpSkqQI",
        "outputId": "34362970-9d5a-4571-811f-15bc97d20e27"
      },
      "source": [
        "#Pruebas con distintas variantes de algoritmos\n",
        "\n",
        "print(105 * '_')\n",
        "print('init\\t\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsilhouette\\tclusters')\n",
        "#K-Means con inicialización al azar\n",
        "kmeans = KMeans(init=\"random\", n_clusters=10)\n",
        "bench_k_means(kmeans=kmeans, name=\"random\", data=MFCCs_data, labels=labels_data)\n",
        "\n",
        "#K-means++\n",
        "kmeans = KMeans(init=\"k-means++\", n_clusters=10)\n",
        "bench_k_means(kmeans=kmeans, name=\"k-means++\", data=MFCCs_data, labels=labels_data)\n",
        "\n",
        "#DBSCAN con épsilon por defecto\n",
        "db = DBSCAN() \n",
        "bench_clustering2(fc=db, name=\"DBSCAN-f 0.5\", data=MFCCs_data, labels=labels_data, all=False)\n",
        "\n",
        "#DBSCAN con épsilon 0.7\n",
        "db = DBSCAN(eps=0.7) \n",
        "bench_clustering2(fc=db, name=\"DBSCAN-f 0.7\", data=MFCCs_data, labels=labels_data, all=False)\n",
        "\n",
        "#DBSCAN con épsilon 0.2\n",
        "db = DBSCAN(eps=0.2) \n",
        "bench_clustering2(fc=db, name=\"DBSCAN-f 0.2\", data=MFCCs_data, labels=labels_data, all=False)\n",
        "\n",
        "#DBSCAN con épsilon por defecto agregando outliers a cluster extra\n",
        "db = DBSCAN() \n",
        "bench_clustering2(fc=db, name=\"DBSCAN-t 0.5\", data=MFCCs_data, labels=labels_data, all=True)\n",
        "\n",
        "#DBSCAN con épsilon 0.7 agregando outliers a cluster extra\n",
        "db = DBSCAN(eps=0.7) \n",
        "bench_clustering2(fc=db, name=\"DBSCAN-t 0.7\", data=MFCCs_data, labels=labels_data, all=True)\n",
        "\n",
        "#DBSCAN con épsilon 0.2 agregando outliers a cluster extra\n",
        "db = DBSCAN(eps=0.2) \n",
        "bench_clustering2(fc=db, name=\"DBSCAN-t 0.2\", data=MFCCs_data, labels=labels_data, all=True)\n",
        "\n",
        "#Clustering aglomerativo\n",
        "Agg = AgglomerativeClustering(n_clusters=10) \n",
        "bench_clustering2(fc=Agg, name=\"Aglomerativo\", data=MFCCs_data, labels=labels_data, all=False)\n",
        "\n",
        "print(105 * '_')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________________________________________________\n",
            "init\t\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsilhouette\tclusters\n",
            "random         \t\t0.694s\t55364\t0.666\t0.517\t0.582\t0.329\t0.581\t0.237\t\t10\n",
            "k-means++      \t\t0.510s\t51637\t0.695\t0.584\t0.635\t0.552\t0.634\t0.245\t\t10\n",
            "DBSCAN-f 0.5   \t\t0.575s\tnan\t1.000\t0.327\t0.493\t0.256\t0.483\t0.235\t\t8\n",
            "DBSCAN-f 0.7   \t\t0.714s\tnan\t1.000\t0.585\t0.738\t0.450\t0.730\t0.509\t\t13\n",
            "DBSCAN-f 0.2   \t\t0.375s\tnan\t1.000\t0.000\t0.000\t0.000\t0.000\t0.517\t\t2\n",
            "DBSCAN-t 0.5   \t\t0.580s\tnan\t0.074\t0.451\t0.127\t0.049\t0.123\t-0.215\t\t9\n",
            "DBSCAN-t 0.7   \t\t0.711s\tnan\t0.179\t0.545\t0.270\t0.133\t0.265\t-0.163\t\t14\n",
            "DBSCAN-t 0.2   \t\t0.388s\tnan\t0.011\t0.677\t0.022\t0.006\t0.021\t-0.096\t\t3\n",
            "Aglomerativo   \t\t2.035s\tnan\t0.789\t0.661\t0.719\t0.590\t0.718\t0.276\t\t10\n",
            "_________________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofcudsK4n2j_"
      },
      "source": [
        "## Pruebas con PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clYLDI_eoAvk",
        "outputId": "084d9208-48a1-49a3-aee8-c8443f76e0ae"
      },
      "source": [
        "#Pruebas con PCA\n",
        "print(105 * '_')\n",
        "print('init\\t\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsilhouette\\tclusters')\n",
        "#K-Means con inicialización al azar\n",
        "reduced_data = PCA(n_components=2).fit_transform(MFCCs_data)\n",
        "kmeans = KMeans(init='random', n_clusters=10)\n",
        "bench_k_means(kmeans=kmeans, name=\"p-random\", data=reduced_data, labels=labels_data)\n",
        "\n",
        "#K-means++\n",
        "kmeans = KMeans(init=\"k-means++\", n_clusters=10)\n",
        "bench_k_means(kmeans=kmeans, name=\"p-k-means++\", data=reduced_data, labels=labels_data)\n",
        "\n",
        "#DBSCAN con épsilon por defecto\n",
        "db = DBSCAN() \n",
        "bench_clustering2(fc=db, name=\"p-DBSCAN-f 0.5\", data=reduced_data, labels=labels_data, all=False)\n",
        "\n",
        "#DBSCAN con épsilon 0.7\n",
        "db = DBSCAN(eps=0.7) \n",
        "bench_clustering2(fc=db, name=\"p-DBSCAN-f 0.7\", data=reduced_data, labels=labels_data, all=False)\n",
        "\n",
        "#DBSCAN con épsilon 0.2\n",
        "db = DBSCAN(eps=0.2) \n",
        "bench_clustering2(fc=db, name=\"p-DBSCAN-f 0.2\", data=reduced_data, labels=labels_data, all=False)\n",
        "\n",
        "#DBSCAN con épsilon por defecto agregando outliers a cluster extra\n",
        "db = DBSCAN() \n",
        "bench_clustering2(fc=db, name=\"p-DBSCAN-t 0.5\", data=reduced_data, labels=labels_data, all=True)\n",
        "\n",
        "#DBSCAN con épsilon 0.7 agregando outliers a cluster extra\n",
        "db = DBSCAN(eps=0.7) \n",
        "bench_clustering2(fc=db, name=\"p-DBSCAN-t 0.7\", data=reduced_data, labels=labels_data, all=True)\n",
        "\n",
        "#DBSCAN con épsilon 0.2 agregando outliers a cluster extra\n",
        "db = DBSCAN(eps=0.2) \n",
        "bench_clustering2(fc=db, name=\"p-DBSCAN-t 0.2\", data=reduced_data, labels=labels_data, all=True)\n",
        "\n",
        "#Clustering aglomerativo\n",
        "Agg = AgglomerativeClustering(n_clusters=10) \n",
        "bench_clustering2(fc=Agg, name=\"p-Aglomerativo\", data=reduced_data, labels=labels_data, all=False)\n",
        "\n",
        "print(105 * '_')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________________________________________________\n",
            "init\t\t\ttime\tinertia\thomo\tcompl\tv-meas\tARI\tAMI\tsilhouette\tclusters\n",
            "p-random       \t\t0.581s\t944\t0.654\t0.496\t0.564\t0.348\t0.563\t0.395\t\t10\n",
            "p-k-means++    \t\t0.307s\t942\t0.671\t0.518\t0.585\t0.404\t0.584\t0.395\t\t10\n",
            "p-DBSCAN-f 0.5 \t\t0.241s\tnan\t0.000\t1.000\t0.000\t0.000\t0.000\tnan\t\t1\n",
            "p-DBSCAN-f 0.7 \t\t0.250s\tnan\t-0.000\t1.000\t-0.000\t0.000\t-0.000\tnan\t\t1\n",
            "p-DBSCAN-f 0.2          No se pueden calcular las métricas\n",
            "p-DBSCAN-t 0.5          No se pueden calcular las métricas\n",
            "p-DBSCAN-t 0.7          No se pueden calcular las métricas\n",
            "p-DBSCAN-t 0.2 \t\t0.109s\tnan\t0.004\t0.103\t0.007\t0.001\t0.005\t0.354\t\t4\n",
            "p-Aglomerativo \t\t1.552s\tnan\t0.649\t0.490\t0.558\t0.350\t0.557\t0.407\t\t10\n",
            "_________________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}